{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1270853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P Naidoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf1fc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scipy\n",
    "!pip install pandas\n",
    "!pip install shutil\n",
    "!pip install opencv-python\n",
    "!pip install tabulate\n",
    "!pip install sympy\n",
    "!pip install scikit-image\n",
    "!apt update && apt install -y libsm6 libxext6\n",
    "!apt apt-get install -y libxrender-dev\n",
    "#!apt-get update\n",
    "!apt-get install ffmpeg libsm6 libxext6  -y\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "\n",
    "import pickle\n",
    "\n",
    "LOCAL_DATA_PATH = '/tf/notebooks/Data/echonet frames split for model training' #'/tf/notebooks/Data/echonet'\n",
    "\n",
    "MODEL_PATH = '/tf/notebooks/Project with Beth/Trained Models/Model training on ECHONET with Tversky loss'\n",
    "\n",
    "SAVE_FOLDER = f'Prediction Results'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848f2178",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f277022",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OUTPUT_CHANNELS = 1 # no of classes\n",
    "BATCH_SIZE = 8      # 8 for GPU Server\n",
    "BUFFER_SIZE = 1000\n",
    "EPOCHS = 100         # 100 for GPU Server\n",
    "INPUT_IMAGE_SIZE_PIXELS = 512\n",
    "INPUT_SHAPE_IMAGE = [512, 512, 1]\n",
    "LEARNING_RATE=0.00001\n",
    "VAL_SUBSPLITS = 5\n",
    "\n",
    "NUM_OF_EXPERIMENTS = 5      #How many times to run each task\n",
    "\n",
    "EARLY_STOPPING_PATIENCE = 10 # 3 is the default value in tensorflow\n",
    "\n",
    "SEED = 24\n",
    "\n",
    "START_PERCENTAGE = 4        #example start at 4% since the initial model was trained at 4% but do not train the first 4%\n",
    "INCREMENT_PERCENTAGE = 1    #increment every k%\n",
    "STOP_PERCENTAGE = 50        #stop at 30% of training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b342bfc",
   "metadata": {},
   "source": [
    "# Functions for reading images, displaying predictions, and callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48795e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_image(img_path: str) -> dict:\n",
    "    \"\"\"Load an image and its annotation (mask) and return a dictionary.\n",
    "\n",
    "    img_path : str : Image (not the mask) location.\n",
    "    dict: Dictionary mapping an image and its annotation.\n",
    "    \"\"\"\n",
    "    image = tf.io.read_file(img_path)\n",
    "    image = tf.image.decode_png(image, channels=1)\n",
    "    image = tf.image.convert_image_dtype(image, tf.uint8)\n",
    "\n",
    "    # For one Image path:\n",
    "    # .../dataset/images/training/im_00000001.jpg\n",
    "    # Its corresponding annotation path is:\n",
    "    # .../dataset/annotations/training/im_00000001.png\n",
    "    mask_path = tf.strings.regex_replace(img_path, \"images\", \"annotations_binary\")\n",
    "    mask_path = tf.strings.regex_replace(mask_path, \"jpg\", \"png\")\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    # The masks contain a class index for each pixels\n",
    "    mask = tf.image.decode_png(mask, channels=1)\n",
    "    # In scene parsing, \"not labeled\" = 255\n",
    "    # But it will mess up with our N_CLASS = 150\n",
    "    # Since 255 means the 255th class, which doesn't exist\n",
    "    #mask = tf.where(mask == 255, np.dtype('uint8').type(0), mask)\n",
    "    # Note that we have to convert the new value (0)\n",
    "    # With the same dtype than the tensor itself    \n",
    "\n",
    "    return {'image': image, 'segmentation_mask': mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb7221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(input_image, input_mask):\n",
    "  input_image = tf.cast(input_image, tf.float32) / 255.0  \n",
    "  return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c63dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(datapoint):\n",
    "  input_image = tf.image.resize(datapoint['image'], (INPUT_IMAGE_SIZE_PIXELS, INPUT_IMAGE_SIZE_PIXELS))\n",
    "  input_mask = tf.image.resize(datapoint['segmentation_mask'], (INPUT_IMAGE_SIZE_PIXELS, INPUT_IMAGE_SIZE_PIXELS))\n",
    "\n",
    "  input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "  return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51acd207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize an image example and its corresponding \n",
    "#mask from the dataset.\n",
    "\n",
    "def display(display_list):\n",
    "  plt.figure(figsize=(15, 15))\n",
    "\n",
    "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "  for i in range(len(display_list)):\n",
    "    plt.subplot(1, len(display_list), i+1)\n",
    "    plt.title(title[i])\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "    plt.axis('off')\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def display1(display_list):\n",
    "  plt.figure(figsize=(15, 15))\n",
    "\n",
    "  title = ['True Mask', 'Predicted Mask']\n",
    "\n",
    "  for i in range(len(display_list)):\n",
    "    plt.subplot(1, len(display_list), i+1)\n",
    "    plt.title(title[i])\n",
    "    plt.imshow(display_list[i])\n",
    "    plt.axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13a9e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(pred_mask):\n",
    "  #pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "  #pred_mask = pred_mask[..., tf.newaxis]\n",
    "  pred_mask = tf.greater(pred_mask, 0.5)\n",
    "  pred_mask = tf.dtypes.cast(pred_mask, tf.float32)\n",
    "  #pred_mask = pred_mask[..., tf.newaxis]\n",
    "  pred_mask = pred_mask[0]\n",
    "  return pred_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947d1d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(dataset=None, num=1):\n",
    "  if dataset:\n",
    "    for image, mask in dataset.take(num):\n",
    "      pred_mask = model.predict(image)\n",
    "      display([image[0], mask[0], create_mask(pred_mask)])\n",
    "  else:\n",
    "    display([sample_image, sample_mask,\n",
    "             create_mask(model.predict(sample_image[tf.newaxis, ...]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f34e668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask2(pred_mask):\n",
    "  #pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "  #pred_mask = pred_mask[..., tf.newaxis]\n",
    "  pred_mask = tf.greater(pred_mask, 0.5)\n",
    "  pred_mask = tf.dtypes.cast(pred_mask, tf.float32)\n",
    "  #pred_mask = pred_mask[..., tf.newaxis]\n",
    "  pred_mask = pred_mask[1]\n",
    "  return pred_mask\n",
    "\n",
    "def show_predictions_manual(image, mask, predicted): \n",
    "    display([image[0], mask[0], create_mask(predicted)])\n",
    "    \n",
    "def show_predictions_manual2(image, mask, predicted): \n",
    "    display([image[0], mask[0], create_mask2(predicted)])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4470242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    clear_output(wait=True)\n",
    "    show_predictions()\n",
    "    print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ffc1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to call above functions:\n",
    "\n",
    "#for images, masks in train.take(2):\n",
    "#  sample_image, sample_mask = images, masks\n",
    "#  display([sample_image, sample_mask])\n",
    "\n",
    "\n",
    "#show_predictions(test_data, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f67c20d",
   "metadata": {},
   "source": [
    "# SAVE FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f4165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_experiment_to_file(directory, filename, index, data):\n",
    "    \n",
    "    new_file_name = f'{filename}.pkl'\n",
    "    if not(index is None):\n",
    "        new_file_name = f'{filename}_{index}.pkl'\n",
    "        \n",
    "    file_name_with_path = os.path.join(directory, new_file_name)\n",
    "    with open(file_name_with_path, 'wb') as filehandle:\n",
    "        pickle.dump(data, filehandle)\n",
    "    \n",
    "def load_experiment_from_file(directory, filename, index):\n",
    "    \n",
    "    new_file_name = f'{filename}.pkl'\n",
    "    if not(index is None):\n",
    "        new_file_name = f'{filename}_{index}.pkl'\n",
    "    \n",
    "    file_name_with_path = os.path.join(directory, new_file_name)\n",
    "    with open(file_name_with_path, 'rb') as filehandle:\n",
    "        return pickle.load(filehandle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63caab1",
   "metadata": {},
   "source": [
    "# Metric Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551b67f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import dice\n",
    "\n",
    "def compute_Dice_coefficient(original_mask, predicted_mask):\n",
    "    '''\n",
    "            2 x Intersection\n",
    "    DICE = -------------------\n",
    "           Union + Intersection\n",
    "           \n",
    "    This could be seen as:\n",
    "    \n",
    "                2 x TP\n",
    "    DICE = -----------------\n",
    "           (FP + TP + FN) + TP\n",
    "    '''\n",
    "    \n",
    "    #a = original_mask.ravel()\n",
    "    #b = predicted_mask.ravel()\n",
    "    \n",
    "    #a = original_mask.flatten()\n",
    "    #b = predicted_mask.flatten()    \n",
    "    \n",
    "    #count1 = (a == 1).sum()\n",
    "    #count2 = (b == 1).sum()\n",
    "    \n",
    "    #count1 = np.count_nonzero(original_mask)\n",
    "    #count2 = np.count_nonzero(predicted_mask)\n",
    "    \n",
    "    a = np.array(original_mask, dtype=np.bool)\n",
    "    a = np.atleast_1d(a)\n",
    "    a = tf.reshape(a, [-1])\n",
    "    \n",
    "    b = np.array(predicted_mask, dtype=np.bool)\n",
    "    b = np.atleast_1d(b)\n",
    "    b = tf.reshape(b, [-1])    \n",
    "    \n",
    "    #dice original code, first attempt\n",
    "    #intersection = np.count_nonzero(a & b)    \n",
    "    #union = np.count_nonzero(a) + np.count_nonzero(b)\n",
    "    #dc = (2. * intersection)/float(union) # + intersection - intersection\n",
    "    \n",
    "    #dice computation, second attempt using scipy function\n",
    "    #dc = dice(a, b)\n",
    "    \n",
    "    #dice computation, third attempt\n",
    "    dc = np.sum(predicted_mask[original_mask==1])*2.0 / (np.sum(predicted_mask) + np.sum(original_mask))\n",
    "    \n",
    "    #All three above produce the same output. The second attemp needs to be subtracted from 1.\n",
    "    \n",
    "    return dc\n",
    "\n",
    "def compute_IoU(original_mask, predicted_mask):    \n",
    "    '''\n",
    "            Intersection\n",
    "    IoU = -------------------\n",
    "                Union\n",
    "           \n",
    "    This could be seen as:\n",
    "    \n",
    "                 TP\n",
    "    IoU = -----------------\n",
    "           (FP + TP + FN)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    a = np.array(original_mask, dtype=np.bool)\n",
    "    a = np.atleast_1d(a)\n",
    "    a = tf.reshape(a, [-1])\n",
    "    \n",
    "    b = np.array(predicted_mask, dtype=np.bool)\n",
    "    b = np.atleast_1d(b)\n",
    "    b = tf.reshape(b, [-1])   \n",
    "    \n",
    "    #IoU Attempt 1\n",
    "    #intersection = np.count_nonzero(a & b)    \n",
    "    #union = (np.count_nonzero(a) + np.count_nonzero(b)) - intersection      \n",
    "    #iou = intersection/union\n",
    "    \n",
    "    #IoU attempt 2\n",
    "    intersection = np.sum(predicted_mask[original_mask==1])\n",
    "    iou = (intersection) / ((np.sum(predicted_mask) + np.sum(original_mask)) - intersection)\n",
    "    \n",
    "    #Attempt 1 and 2 above produce the same output. i.e. both works.\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b7b616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import directed_hausdorff\n",
    "\n",
    "def compute_Hausdorff_distance(original_mask, predicted_mask):\n",
    "    '''\n",
    "    We're going to use the Distance Map(Distance Transform) method of computing the Hausdorf distance.\n",
    "    A python library Scipy has a function that can do this for us called distance_transform_edt.\n",
    "    After computing the distance map for mask2 i.e DM2, we need to overlap the boundary of mask1 onto \n",
    "    DM2. The take the maximum value in DM2 where mask1 overlaps. \n",
    "    This maximum value will be the Hausdorf distance d(mask1, mask2).\n",
    "    Then we need to find the Hausdorf distance d(mask2, mask1).\n",
    "    The final distance will be the max(d(mask1, mask2), d(mask2, mask1))\n",
    "    \n",
    "    However, first lets try to do this using scipy.spatial.distance.directed_hausdorf\n",
    "    \n",
    "    Note: for distance, should we use Euclidean or Manhattan etc?\n",
    "    \n",
    "    https://en.wikipedia.org/wiki/Distance_transform\n",
    "    \n",
    "    https://cs.stackexchange.com/questions/117989/hausdorff-distance-between-two-binary-images-according-to-distance-maps\n",
    "    \n",
    "    https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.morphology.distance_transform_edt.html\n",
    "    \n",
    "    Paper: AN IMAGE ALGORITHM FOR COMPUTING THE SDORFF DISTANCE EFFICIENTLY IN LINEAR TIME\n",
    "    Paper: A Linear Time Algorithm of Computing Hausdorff Distance for Content-based Image Analysis    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    hd1 = directed_hausdorff(original_mask, predicted_mask)[0]\n",
    "    hd2 = directed_hausdorff(predicted_mask, original_mask)[0]\n",
    "    \n",
    "    return max(hd1, hd2)    \n",
    "    #return 0\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2e490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient\n",
    "# https://en.wikipedia.org/wiki/Jaccard_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d44c3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_metrics(model, testing_data, num_test_examples, uncertainty = False, dropout = False):\n",
    "    \n",
    "    sum_dice=0\n",
    "    #sum_IoU=0\n",
    "    sum_dH=0\n",
    "    c=0\n",
    "    \n",
    "    uncertainty = 0;\n",
    "    \n",
    "    all_distances={}\n",
    "    \n",
    "    all_uncertainties={}\n",
    "    \n",
    "    for image, mask in testing_data.take(num_test_examples):\n",
    "    \n",
    "        predicted = None\n",
    "        if(dropout):\n",
    "            predicted = model(image, training = True).numpy()\n",
    "        else:\n",
    "            predicted = model.predict(image)\n",
    "            \n",
    "        predicted_mask = create_mask(predicted)  \n",
    "\n",
    "        predicted_mask = predicted_mask.numpy()\n",
    "        predicted_mask = predicted_mask[:, :, 0] #drop the third dimension here since its 512x512x1\n",
    "\n",
    "        ground_truth_mask = mask[0].numpy()\n",
    "        ground_truth_mask = ground_truth_mask[:, :, 0]   \n",
    "\n",
    "        DC = compute_Dice_coefficient(ground_truth_mask, predicted_mask)\n",
    "        #IoU = compute_IoU(ground_truth_mask, predicted_mask)\n",
    "        dH = compute_Hausdorff_distance(ground_truth_mask, predicted_mask)\n",
    "        \n",
    "        if(uncertainty):\n",
    "            uncertainty = compute_uncertainty(predicted[0])\n",
    "            all_uncertainties[c] = uncertainty\n",
    "        #show_predictions_manual(image, mask, predicted)        \n",
    "\n",
    "        #show top 5\n",
    "        #if(c<5):\n",
    "        #    print(f'Dice coefficient: {DC}')\n",
    "        #    print(f'Loss: {1-DC}')\n",
    "        #    print(f'IoU: {IoU}')\n",
    "        #    print(f'Hausdorff Distance: {dH}')\n",
    "        #    print()\n",
    "            #print(f'Jaccard Index:{J_Index}')        \n",
    "            \n",
    "        all_distances[c] = dH        \n",
    "        sum_dice += DC\n",
    "        #sum_IoU += IoU\n",
    "        sum_dH += dH\n",
    "        c += 1\n",
    "        \n",
    "    avg_dice = (sum_dice)/num_test_examples\n",
    "    #avg_IoU = (sum_IoU)/num_test_examples\n",
    "    avg_dH = (sum_dH)/num_test_examples\n",
    "        \n",
    "\n",
    "    return avg_dice, avg_dH, all_distances, all_uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944714fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_metrics_with_masks(model, testing_data, num_test_examples, mute = True):\n",
    "    \n",
    "    sum_dice=0\n",
    "    sum_IoU=0\n",
    "    sum_dH=0\n",
    "    c=0\n",
    "    \n",
    "    uncertainty = 0;\n",
    "    \n",
    "    all_distances={}\n",
    "    \n",
    "    all_uncertainties={}\n",
    "    \n",
    "    all_predicted_masks = {}\n",
    "    \n",
    "    all_ground_truth_masks = {}\n",
    "    \n",
    "    for image, mask in testing_data.take(num_test_examples):\n",
    "    \n",
    "        predicted = model.predict(image)\n",
    "        predicted_mask = create_mask(predicted)  \n",
    "\n",
    "        predicted_mask = predicted_mask.numpy()\n",
    "        predicted_mask = predicted_mask[:, :, 0] #drop the third dimension here since its 512x512x1\n",
    "\n",
    "        ground_truth_mask = mask[0].numpy()\n",
    "        ground_truth_mask = ground_truth_mask[:, :, 0]   \n",
    "\n",
    "        DC = compute_Dice_coefficient(ground_truth_mask, predicted_mask)\n",
    "        IoU = compute_IoU(ground_truth_mask, predicted_mask)\n",
    "        dH = compute_Hausdorff_distance(ground_truth_mask, predicted_mask)\n",
    "        #DC = 0\n",
    "        #IoU = 0\n",
    "        #dH = 0\n",
    "        \n",
    "        uncertainty = compute_uncertainty(predicted[0])\n",
    "        #show_predictions_manual(image, mask, predicted)        \n",
    "\n",
    "        #show top 5\n",
    "        #if(c<5):\n",
    "        #    print(f'Dice coefficient: {DC}')\n",
    "        #    print(f'Loss: {1-DC}')\n",
    "        #    print(f'IoU: {IoU}')\n",
    "        #    print(f'Hausdorff Distance: {dH}')\n",
    "        #    print()\n",
    "            #print(f'Jaccard Index:{J_Index}')\n",
    "            \n",
    "        all_predicted_masks[c] = predicted_mask\n",
    "        all_ground_truth_masks[c] = ground_truth_mask\n",
    "            \n",
    "        all_distances[c] = dH\n",
    "        all_uncertainties[c] = uncertainty\n",
    "        sum_dice += DC\n",
    "        sum_IoU += IoU\n",
    "        sum_dH += dH\n",
    "        c += 1\n",
    "        \n",
    "    avg_dice = (sum_dice)/num_test_examples\n",
    "    avg_IoU = (sum_IoU)/num_test_examples\n",
    "    avg_dH = (sum_dH)/num_test_examples\n",
    "    \n",
    "    if mute == False:\n",
    "        print()\n",
    "        print(f'The average Dice is {avg_dice}')\n",
    "        print(f'The average IoU is {avg_IoU}')\n",
    "        print(f'The average Hausdorff Distance is {avg_dH}')\n",
    "        print()\n",
    "\n",
    "    return avg_dice, avg_IoU, avg_dH, all_distances, all_uncertainties, all_predicted_masks, all_ground_truth_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445f242a",
   "metadata": {},
   "source": [
    "# Prepare Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07bdf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "\n",
    "# callback_early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=EARLY_STOPPING_PATIENCE, verbose=1, restore_best_weights=True)\n",
    "\n",
    "# shape = shape=(2, 2)\n",
    "# initializer = tf.initializers.he_normal()\n",
    "# var = tf.Variable(initializer(shape=shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a3fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(files):\n",
    "    \n",
    "    imgs = tf.data.Dataset.from_tensor_slices(files)\n",
    "    parse_set = imgs.map(parse_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    load_set = parse_set.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    data = load_set.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "    \n",
    "    return data\n",
    "        \n",
    "def get_Hausdorff_distance(predicted_masks, ground_truth_masks):\n",
    "    \n",
    "    num_examples = len(predicted_masks)\n",
    "    all_dHs = {}\n",
    "    sum_dH = 0    \n",
    "    \n",
    "    for i in range(num_examples):\n",
    "        ground_truth_mask = ground_truth_masks[i]\n",
    "        predicted_mask = predicted_masks[i]\n",
    "        dH = compute_Hausdorff_distance(ground_truth_mask, predicted_mask)\n",
    "        sum_dH+= dH\n",
    "        all_dHs[i] = dH\n",
    "        \n",
    "    avg_dH = (sum_dH)/num_examples\n",
    "    \n",
    "    return avg_dH, all_dHs\n",
    "\n",
    "def get_Dice_Coefficient(predicted_masks, ground_truth_masks):\n",
    "    \n",
    "    num_examples = len(predicted_masks)\n",
    "    all_dice = {}\n",
    "    sum_dice = 0    \n",
    "    \n",
    "    for i in range(num_examples):\n",
    "        ground_truth_mask = ground_truth_masks[i]\n",
    "        predicted_mask = predicted_masks[i]\n",
    "        DC = compute_Dice_coefficient(ground_truth_mask, predicted_mask)\n",
    "        sum_dice+= DC\n",
    "        all_dice[i] = DC\n",
    "        \n",
    "    avg_dice = (sum_dice)/num_examples\n",
    "    \n",
    "    return avg_dice, all_dice\n",
    "        \n",
    "def make_predictions(model, image_files):     \n",
    "    \n",
    "    c=0    \n",
    "    \n",
    "    all_predicted_masks = {}\n",
    "    \n",
    "    all_ground_truth_masks = {}\n",
    "    \n",
    "    all_probabilities = {}\n",
    "    \n",
    "    for filename in image_files:\n",
    "        \n",
    "        image = tf.io.read_file(filename)\n",
    "        if ('jpg' in filename):\n",
    "            image = tf.image.decode_jpeg(image, channels=1)\n",
    "        else:\n",
    "            image = tf.image.decode_png(image, channels=1)\n",
    "        image = tf.image.convert_image_dtype(image, tf.uint8)\n",
    "        \n",
    "        mask_path = tf.strings.regex_replace(filename, \"images\", \"annotations_binary\")\n",
    "        mask_path = tf.strings.regex_replace(mask_path, \".jpg\", \".png\")\n",
    "        mask = tf.io.read_file(mask_path)\n",
    "        # The masks contain a class index for each pixels\n",
    "        mask = tf.image.decode_png(mask, channels=1)        \n",
    "\n",
    "        datapoint = {'image': image, 'segmentation_mask': mask}\n",
    "        \n",
    "        input_image = tf.image.resize(datapoint['image'], (INPUT_IMAGE_SIZE_PIXELS, INPUT_IMAGE_SIZE_PIXELS))\n",
    "        input_mask = tf.image.resize(datapoint['segmentation_mask'], (INPUT_IMAGE_SIZE_PIXELS, INPUT_IMAGE_SIZE_PIXELS))  \n",
    "        input_image, input_mask = normalize(input_image, input_mask)\n",
    "        \n",
    "        image = input_image\n",
    "        mask = input_mask\n",
    "        \n",
    "        image_reshape = tf.expand_dims(image,0)        \n",
    "        predicted = model.predict(image_reshape)\n",
    "        predicted_mask = create_mask(predicted)  \n",
    "\n",
    "        predicted_mask = predicted_mask.numpy()        \n",
    "        predicted_mask = predicted_mask[:, :, 0] #drop the third dimension here since its 512x512x1\n",
    "\n",
    "        ground_truth_mask = mask.numpy()\n",
    "        ground_truth_mask = ground_truth_mask[:, :, 0]           \n",
    "        \n",
    "        all_predicted_masks[c] = predicted_mask\n",
    "        all_ground_truth_masks[c] = ground_truth_mask        \n",
    "        all_probabilities[c] = predicted[0]       \n",
    "        \n",
    "        c += 1\n",
    "    \n",
    "\n",
    "    return all_predicted_masks, all_ground_truth_masks, all_probabilities\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2f2517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rgb_image(predicted_mask):\n",
    "\n",
    "    img_temp_np = np.zeros((predicted_mask.shape[0],predicted_mask.shape[1],3))\n",
    "\n",
    "\n",
    "    for i in range(predicted_mask.shape[0]):\n",
    "         for j in range(predicted_mask.shape[1]):\n",
    "             if predicted_mask[i,j] == 1:\n",
    "                img_temp_np[i,j] = (int(255),int(255),int(255))\n",
    "             else:\n",
    "                img_temp_np[i,j] = (int(0),int(0),int(0))\n",
    "\n",
    "    img = img_temp_np.astype(np.uint8)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def get_binary_image(mask):\n",
    "\n",
    "    img_temp_np = np.zeros((mask.shape[0],mask.shape[1]))\n",
    "\n",
    "\n",
    "    for i in range(mask.shape[0]):\n",
    "         for j in range(mask.shape[1]):\n",
    "            #if np.array_equal(mask[i,j], np.asarray((255,255,255))):             \n",
    "            if mask[i,j][0] > 0:            \n",
    "                img_temp_np[i,j] = 1\n",
    "            else:\n",
    "                img_temp_np[i,j] = 0\n",
    "\n",
    "    img = img_temp_np.astype(np.uint8)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def draw_poly_on_image(img, coordinates, color, use_weight=True):\n",
    "    pts = np.array(coordinates, np.int32)\n",
    "    pts = pts.reshape((-1,1,2))\n",
    "    \n",
    "    weight = 1\n",
    "    if (use_weight):\n",
    "        weight = 2\n",
    "        \n",
    "    img = cv2.polylines(img, [pts], True, color, thickness=weight)\n",
    "    return img\n",
    "\n",
    "def draw_poly_on_image_weight(img, coordinates, color, weight=1):\n",
    "    pts = np.array(coordinates, np.int32)\n",
    "    pts = pts.reshape((-1,1,2))    \n",
    "        \n",
    "    img = cv2.polylines(img, [pts], True, color, thickness=weight)\n",
    "    return img\n",
    "\n",
    "\n",
    "def fill_poly_on_image(img, coordinates, color):\n",
    "    \n",
    "    pts = np.array(coordinates, np.int32)\n",
    "    pts = pts.reshape((-1,1,2))\n",
    "    img = cv2.fillPoly(img, [pts], color)\n",
    "    return img\n",
    "\n",
    "\n",
    "def draw_line_on_image(img, x1, y1, x2, y2, color, use_weight=True):\n",
    "    \n",
    "    weight = 1\n",
    "    if (use_weight):\n",
    "        weight = 2\n",
    "        \n",
    "    img = cv2.line(img, (int(x1), int(y1)), (int(x2), int(y2)), color, thickness=weight)\n",
    "    return img\n",
    "\n",
    "\n",
    "def draw_circle_on_image(img, x1, y1, radius, color, use_weight=True):\n",
    "    \n",
    "    weight = 1\n",
    "    if (use_weight):\n",
    "        weight = 2\n",
    "        \n",
    "    img = cv2.circle(img,(int(x1),int(y1)), radius, color, thickness=weight)\n",
    "    return img\n",
    "\n",
    "\n",
    "def show_image(img):\n",
    "    cv2.imshow('hello_world',img)\n",
    "\n",
    "    #waitKey() waits for a key press to close the window and 0 specifies indefinite loop\n",
    "    #cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows() simply destroys all the windows we created.\n",
    "    #cv2.destroyAllWindows()\n",
    "    c = cv2.waitKey()\n",
    "    if(c>=0):\n",
    "        return -1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def get_p_at_d(p,v,d):\n",
    "    v2 = (v[0]*d, v[1]*d)\n",
    "    pTemp = (p[0]+v2[0], p[1]+v2[1])\n",
    "    return pTemp\n",
    "\n",
    "def get_norm(v):\n",
    "    vd = math.sqrt(v[0]*v[0]+v[1]*v[1])\n",
    "    v_norm = (v[0]/vd, v[1]/vd)\n",
    "    return v_norm\n",
    "\n",
    "def get_dist(p1, p2):\n",
    "    d = math.sqrt(pow(p2[0]-p1[0],2) + pow(p2[1]-p1[1],2))\n",
    "    return d\n",
    "\n",
    "def get_mid(p1, p2):\n",
    "    return ((p1[0]+p2[0])/2.0, (p1[1]+p2[1])/2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a9dfd1",
   "metadata": {},
   "source": [
    "# Cleaned Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba862b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "from sympy import Point, Polygon, Line\n",
    "from skimage.draw import line\n",
    "\n",
    "def get_mask_volume(mask, K=20, is_binary_image = True):\n",
    "    '''\n",
    "    Computes the volume of the mask with the assumption that the \n",
    "    the the width of the segments are used as the radius of a cylinder.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mask : numpy array of 2 or 3 dimensions\n",
    "           This is a binary mask which means the values contained within\n",
    "           the array are 1 and 0 only.\n",
    "    K : int, optional\n",
    "        The number of segments(or cylinders) to divide the mask into. \n",
    "        The default is 20. \n",
    "        The greater the number the better the volume approximation, however,\n",
    "        the more computationally expensive it becomes.\n",
    "    is_binary_image : bool, optional\n",
    "        if true, then the input mask is expected to be a binary image.\n",
    "        Otherwise, it is a normal rgb image.\n",
    "        Example, if you're passing in an np.array from \n",
    "        tensorflow.model.predict' for a segmentation binary classification \n",
    "        problem, then this would be a binary image or binary mask.\n",
    "    use_bottom_midpoint : bool, optional\n",
    "        if this is true, the segments are based on the centerline from the \n",
    "        maximum point(top of LV) to the midpoint at the bottom of the LV. \n",
    "        If False, then the centerline runs from the max point to the min point.\n",
    "        The default is True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    use_bottom_midpoint = True\n",
    "\n",
    "    poly_points = None\n",
    "    midpointline = None\n",
    "    minmaxline = None\n",
    "    segments = None\n",
    "    \n",
    "    adj_mask = mask.copy()\n",
    "    \n",
    "    if is_binary_image:\n",
    "        if(len(mask.shape) == 3):\n",
    "            adj_mask = mask[:, :, 0]\n",
    "    \n",
    "    mask_rgb = adj_mask\n",
    "    \n",
    "    if is_binary_image:\n",
    "        mask_rgb = get_rgb_image(adj_mask)\n",
    "\n",
    "    #Get polyline of the mask    \n",
    "    image_test1_gray = cv2.cvtColor(mask_rgb, cv2.COLOR_BGR2GRAY)\n",
    "    contours, hierarchy = cv2.findContours(image_test1_gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    largest_index_area = 0\n",
    "    largest_area = -1\n",
    "    for i in range(0, len(contours)):\n",
    "        area = cv2.contourArea(contours[i])\n",
    "        if (area > largest_area):\n",
    "            largest_area = area\n",
    "            largest_index_area = i\n",
    "\n",
    "\n",
    "    #Get the shape/polyline of the largest area    \n",
    "    poly_points = contours[largest_index_area]    \n",
    "    \n",
    "    #get the bounds\n",
    "    box = cv2.boundingRect(poly_points);\n",
    "    length_vert = (box[1]+box[3]) - box[1]\n",
    "    length_hori = (box[0]+box[2]) - box[0]\n",
    "    min_row = box[1] - length_vert\n",
    "    max_row = box[1] + box[3] + length_vert\n",
    "    min_col = box[0] - length_hori\n",
    "    max_col = box[0] + box[2] + length_hori\n",
    "\n",
    "    #Find the two points furthest apart\n",
    "    #While looping through all points, Also find the bottom-left most point and the bottom-right most point\n",
    "    index1 = -1\n",
    "    index2 = -1\n",
    "    dr = -999999999999.00\n",
    "    d_left = 999999999999.00\n",
    "    d_right = 999999999999.00\n",
    "    left_index = -1\n",
    "    right_index = -1\n",
    "    for i in range(len(poly_points)):\n",
    "        coord1 = poly_points[i][0]\n",
    "        x1 = coord1[0]\n",
    "        y1 = coord1[1]\n",
    "        for j in range(len(poly_points)):\n",
    "            if(i==j):\n",
    "                continue\n",
    "            coord2 = poly_points[j][0]\n",
    "            x2 = coord2[0]\n",
    "            y2 = coord2[1]        \n",
    "\n",
    "            d = math.sqrt(pow(x2-x1,2) + pow(y2-y1,2))\n",
    "            if(d>dr):\n",
    "                dr = d\n",
    "                index1 = i\n",
    "                index2 = j\n",
    "        \n",
    "        d1 = get_dist(coord1, (min_col, max_row))\n",
    "        d2 = get_dist(coord1,(max_col, max_row))\n",
    "        if(d1 < d_left):\n",
    "            d_left = d1\n",
    "            left_index = i\n",
    "        if(d2 < d_right):\n",
    "            d_right = d2\n",
    "            right_index = i        \n",
    "\n",
    "    coord1 = poly_points[index1][0]\n",
    "    coord2 = poly_points[index2][0]\n",
    "    \n",
    "    #Find min and max and get vect between them\n",
    "    minP = None\n",
    "    maxP = None\n",
    "\n",
    "    if(coord1[1] > coord2[1]):\n",
    "        minP = coord1\n",
    "        maxP = coord2\n",
    "    else:\n",
    "        minP = coord2\n",
    "        maxP = coord1\n",
    "        \n",
    "    minmaxline = [minP, maxP]\n",
    "        \n",
    "    #Get the midpoint\n",
    "    leftMost = poly_points[left_index][0]\n",
    "    rightMost = poly_points[right_index][0]\n",
    "    mid_temp = get_mid(leftMost, rightMost)    \n",
    "    \n",
    "    #create sympy polygon object\n",
    "    pts_temp = []\n",
    "    for i in range(len(poly_points)):\n",
    "        coord = poly_points[i][0]\n",
    "        x1 = coord[0]\n",
    "        y1 = coord[1]\n",
    "        pt = Point(x1,y1)\n",
    "        pts_temp.append(pt)\n",
    "    poly = Polygon(*pts_temp)\n",
    "    \n",
    "    #Get vector from max point to mid point\n",
    "    v1 = (maxP[0] - mid_temp[0], maxP[1] - mid_temp[1])\n",
    "    vd = math.sqrt(v1[0]*v1[0]+v1[1]*v1[1])\n",
    "    v1norm = (v1[0]/vd, v1[1]/vd)\n",
    "    \n",
    "    #Find the true midpoint     \n",
    "    p1_temp = get_p_at_d(maxP, v1norm, dr/10.0)\n",
    "    p2_temp = get_p_at_d(maxP, v1norm, -dr*1.1)    \n",
    "    int_pts_temp = poly.intersection(Line(p1_temp, p2_temp))    \n",
    "    true_mid = None\n",
    "    #There should only be 2 points of intersection\n",
    "    if(len(int_pts_temp) >= 2):\n",
    "        if(get_dist(mid_temp, int_pts_temp[0]) < get_dist(mid_temp, int_pts_temp[1])):\n",
    "            true_mid = int_pts_temp[0]\n",
    "        else:\n",
    "            true_mid = int_pts_temp[1]\n",
    "    else:\n",
    "        true_mid = mid_temp\n",
    "    \n",
    "    midpointline = [true_mid, maxP]\n",
    "    \n",
    "    startPt = maxP\n",
    "    endPt = minP\n",
    "    if(use_bottom_midpoint):\n",
    "        endPt = true_mid\n",
    "    \n",
    "    #Get vector from start point to end point\n",
    "    v1 = (endPt[0] - startPt[0], endPt[1] - startPt[1])\n",
    "    vd = math.sqrt(v1[0]*v1[0]+v1[1]*v1[1])\n",
    "    v1norm = (v1[0]/vd, v1[1]/vd)      \n",
    "\n",
    "    #Get step size/distance    \n",
    "    distance = get_dist(startPt, endPt) \n",
    "    h = distance/K    \n",
    "#     d_test = int(h*float(K))    \n",
    "#     true_k = K\n",
    "#     if(d_test>distance):\n",
    "#         true_k = true_k-1    \n",
    "    true_k = K\n",
    "\n",
    "    #Variables for the loop initialisation\n",
    "    start = (startPt[0], startPt[1])\n",
    "    start = get_p_at_d(start, v1norm, -h)\n",
    "    vol = 0\n",
    "    segments = []    \n",
    "    start = startPt\n",
    "    has_intersections = True\n",
    "    while(has_intersections):        \n",
    "        width = 0\n",
    "        \n",
    "        #Get point along the line starting from startPt and taking a distance of h\n",
    "        #Get vect between the next point and the previous point    \n",
    "        end = get_p_at_d(start, (v1norm[0], v1norm[1]), h)        \n",
    "        vH = (end[0] - start[0], end[1] - start[1])\n",
    "        start = (end[0], end[1])\n",
    "        \n",
    "        #Safety to get out of the loop\n",
    "        if(get_dist(startPt, end) > distance*1.5):\n",
    "            has_intersections = False\n",
    "            break\n",
    "        \n",
    "        #Rotate vect by 90 to get the horizontal cutting line\n",
    "        vPerp = (vH[1],vH[0]*-1.0)\n",
    "        vPerp_norm = get_norm(vPerp)\n",
    "\n",
    "        #Extend length of horizontal line to make sure it cuts\n",
    "        phoriz1 = get_p_at_d(end, vPerp_norm, -dr/2.0)\n",
    "        phoriz2 = get_p_at_d(end, vPerp_norm, dr/2.0)        \n",
    "        \n",
    "        p1 = Point(phoriz1[0], phoriz1[1])\n",
    "        p2 = Point(phoriz2[0], phoriz2[1])\n",
    "        int_pts = poly.intersection(Line(p1, p2))        \n",
    "        \n",
    "        if(len(int_pts) == 2):\n",
    "            int1 = int_pts[0]\n",
    "            int2 = int_pts[1]\n",
    "            int_pt1 = (float(int1.x),float(int1.y))\n",
    "            int_pt2 = (float(int2.x),float(int2.y))\n",
    "            width = get_dist(int_pt1, int_pt2)            \n",
    "            segments.append((int_pt1,int_pt2)) \n",
    "            \n",
    "        elif (len(int_pts) > 2):                  \n",
    "            \n",
    "            for i in range(len(int_pts)-1):                      \n",
    "                \n",
    "                coord1 = int_pts[i]\n",
    "                coord2 = int_pts[i+1]                \n",
    "                \n",
    "                int_pt1 = (float(coord1.x),float(coord1.y))\n",
    "                int_pt2 = (float(coord2.x),float(coord2.y))\n",
    "                width += get_dist(int_pt1, int_pt2)                \n",
    "            \n",
    "            #just append the first and last for now\n",
    "            p1 = int_pts[0]\n",
    "            p2 = int_pts[len(int_pts)-1]\n",
    "            ip1 = (float(p1.x),float(p1.y))\n",
    "            ip2 = (float(p2.x),float(p2.y))\n",
    "            segments.append((ip1,ip2)) \n",
    "        else:\n",
    "            #len(int_pts) is zero or one here\n",
    "            has_intersections = False\n",
    "            break\n",
    "        \n",
    "        rad = width/2.0\n",
    "        vol += math.pi*rad*rad*h   \n",
    "    \n",
    "    return vol, poly_points, minmaxline, midpointline, segments\n",
    "\n",
    "\n",
    "\n",
    "def get_intersection(mask_rgb, poly_points, line_pt1, line_pt2):\n",
    "    \n",
    "    temp_mask_rgb = mask_rgb.copy()    \n",
    "    \n",
    "    #red\n",
    "    temp_mask_rgb = draw_line_on_image(temp_mask_rgb, line_pt1[0], line_pt1[1], line_pt2[0], line_pt2[1], (255,0,0), use_weight=True)\n",
    "    \n",
    "    #green\n",
    "    temp_mask_rgb = fill_poly_on_image(temp_mask_rgb, poly_points, (0,255,0))\n",
    "    \n",
    "    #cyan\n",
    "    temp_mask_rgb = draw_poly_on_image(temp_mask_rgb, poly_points, (255,255,0), use_weight = False)    \n",
    "    \n",
    "    pt1 = (int(line_pt1[0]), int(line_pt1[1]))\n",
    "    pt2 = (int(line_pt2[0]), int(line_pt2[1]))\n",
    "    discrete_line = list(zip(*line(*pt1, *pt2)))    \n",
    "    \n",
    "    int_pts = []\n",
    "    prev_pix = (0,0,0)\n",
    "    for i in range(len(discrete_line)):\n",
    "        coord = discrete_line[i]        \n",
    "        \n",
    "        if(abs(coord[1])>=temp_mask_rgb.shape[0] or abs(coord[0])>=temp_mask_rgb.shape[1]):\n",
    "            continue\n",
    "            \n",
    "        if(coord[0] <= 0):\n",
    "            continue\n",
    "            \n",
    "        if(coord[1] <= 0):\n",
    "            continue\n",
    "            \n",
    "        pix = temp_mask_rgb[int(coord[1]), int(coord[0])]        \n",
    "        \n",
    "        if np.array_equal(pix, np.asarray((255,255,0))):\n",
    "            int_pts.append(coord)\n",
    "        elif i > 0:\n",
    "            #check for change in transition            \n",
    "            if(np.array_equal(prev_pix, np.asarray((255,0,0))) and np.array_equal(pix, np.asarray((0,255,0)))):\n",
    "                int_pts.append(coord)\n",
    "            elif(np.array_equal(prev_pix, np.asarray((0,255,0))) and np.array_equal(pix, np.asarray((255,0,0)))):\n",
    "                int_pts.append(coord)                \n",
    "        \n",
    "        prev_pix = pix\n",
    "        \n",
    "    return int_pts\n",
    "\n",
    "\n",
    "\n",
    "def get_mask_volume_quick(mask, K=20, is_binary_image = True):\n",
    "    '''\n",
    "    Computes the volume of the mask with the assumption that the \n",
    "    the the width of the segments are used as the radius of a cylinder.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mask : numpy array of 2 or 3 dimensions\n",
    "           This is a binary mask which means the values contained within\n",
    "           the array are 1 and 0 only.\n",
    "    K : int, optional\n",
    "        The number of segments(or cylinders) to divide the mask into. \n",
    "        The default is 20. \n",
    "        The greater the number the better the volume approximation, however,\n",
    "        the more computationally expensive it becomes.\n",
    "    is_binary_image : bool, optional\n",
    "        if true, then the input mask is expected to be a binary image.\n",
    "        Otherwise, it is a normal rgb image.\n",
    "        Example, if you're passing in an np.array from \n",
    "        tensorflow.model.predict' for a segmentation binary classification \n",
    "        problem, then this would be a binary image or binary mask.\n",
    "    use_bottom_midpoint : bool, optional\n",
    "        if this is true, the segments are based on the centerline from the \n",
    "        maximum point(top of LV) to the midpoint at the bottom of the LV. \n",
    "        If False, then the centerline runs from the max point to the min point.\n",
    "        The default is True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    use_bottom_midpoint = True\n",
    "\n",
    "    poly_points = None\n",
    "    midpointline = None\n",
    "    minmaxline = None\n",
    "    segments = None\n",
    "    \n",
    "    adj_mask = mask.copy()\n",
    "    \n",
    "    if is_binary_image:\n",
    "        if(len(mask.shape) == 3):\n",
    "            adj_mask = mask[:, :, 0]\n",
    "    \n",
    "    mask_rgb = adj_mask\n",
    "    \n",
    "    if is_binary_image:\n",
    "        mask_rgb = get_rgb_image(adj_mask)\n",
    "\n",
    "    #Get polyline of the mask    \n",
    "    image_test1_gray = cv2.cvtColor(mask_rgb, cv2.COLOR_BGR2GRAY)\n",
    "    contours, hierarchy = cv2.findContours(image_test1_gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    largest_index_area = 0\n",
    "    largest_area = -1\n",
    "    for i in range(0, len(contours)):\n",
    "        area = cv2.contourArea(contours[i])\n",
    "        if (area > largest_area):\n",
    "            largest_area = area\n",
    "            largest_index_area = i\n",
    "    \n",
    "    if(largest_area <= 0):\n",
    "        return 0, None, None, None, None\n",
    "\n",
    "    #Get the shape/polyline of the largest area    \n",
    "    poly_points = contours[largest_index_area]    \n",
    "    \n",
    "    #get the bounds\n",
    "    box = cv2.boundingRect(poly_points);\n",
    "    length_vert = (box[1]+box[3]) - box[1]\n",
    "    length_hori = (box[0]+box[2]) - box[0]\n",
    "    min_row = box[1] - length_vert\n",
    "    max_row = box[1] + box[3] + length_vert\n",
    "    min_col = box[0] - length_hori\n",
    "    max_col = box[0] + box[2] + length_hori\n",
    "\n",
    "    #Find the two points furthest apart\n",
    "    #While looping through all points, Also find the bottom-left most point and the bottom-right most point\n",
    "    index1 = -1\n",
    "    index2 = -1\n",
    "    dr = -999999999999.00\n",
    "    d_left = 999999999999.00\n",
    "    d_right = 999999999999.00\n",
    "    left_index = -1\n",
    "    right_index = -1\n",
    "    for i in range(len(poly_points)):\n",
    "        coord1 = poly_points[i][0]\n",
    "        x1 = coord1[0]\n",
    "        y1 = coord1[1]\n",
    "        for j in range(len(poly_points)):\n",
    "            if(i==j):\n",
    "                continue\n",
    "            coord2 = poly_points[j][0]\n",
    "            x2 = coord2[0]\n",
    "            y2 = coord2[1]        \n",
    "\n",
    "            d = math.sqrt(pow(x2-x1,2) + pow(y2-y1,2))\n",
    "            if(d>dr):\n",
    "                dr = d\n",
    "                index1 = i\n",
    "                index2 = j\n",
    "        \n",
    "        d1 = get_dist(coord1, (min_col, max_row))\n",
    "        d2 = get_dist(coord1,(max_col, max_row))\n",
    "        if(d1 < d_left):\n",
    "            d_left = d1\n",
    "            left_index = i\n",
    "        if(d2 < d_right):\n",
    "            d_right = d2\n",
    "            right_index = i        \n",
    "\n",
    "    coord1 = poly_points[index1][0]\n",
    "    coord2 = poly_points[index2][0]\n",
    "    \n",
    "    #Find min and max and get vect between them\n",
    "    minP = None\n",
    "    maxP = None\n",
    "\n",
    "    if(coord1[1] > coord2[1]):\n",
    "        minP = coord1\n",
    "        maxP = coord2\n",
    "    else:\n",
    "        minP = coord2\n",
    "        maxP = coord1\n",
    "        \n",
    "    minmaxline = [minP, maxP]\n",
    "        \n",
    "    #Get the midpoint\n",
    "    leftMost = poly_points[left_index][0]\n",
    "    rightMost = poly_points[right_index][0]\n",
    "    mid_temp = get_mid(leftMost, rightMost)    \n",
    "    \n",
    "    #create sympy polygon object\n",
    "    pts_temp = []\n",
    "    for i in range(len(poly_points)):\n",
    "        coord = poly_points[i][0]\n",
    "        x1 = coord[0]\n",
    "        y1 = coord[1]\n",
    "        pt = Point(x1,y1)\n",
    "        pts_temp.append(pt)    \n",
    "    \n",
    "    #Get vector from max point to mid point\n",
    "    v1 = (maxP[0] - mid_temp[0], maxP[1] - mid_temp[1])\n",
    "    vd = math.sqrt(v1[0]*v1[0]+v1[1]*v1[1])\n",
    "    v1norm = (v1[0]/vd, v1[1]/vd)    \n",
    "    \n",
    "    #Find the true midpoint     \n",
    "    p1_temp = get_p_at_d(maxP, v1norm, dr)\n",
    "    p2_temp = get_p_at_d(maxP, v1norm, -dr*1.10)    \n",
    "    \n",
    "    int_pts_temp = get_intersection(mask_rgb, poly_points, p1_temp, p2_temp)   \n",
    "    pts_len = len(int_pts_temp)\n",
    "    true_mid = None\n",
    "    #There should only be 2 points of intersection\n",
    "    if(len(int_pts_temp) >= 2):\n",
    "        if(get_dist(mid_temp, int_pts_temp[0]) < get_dist(mid_temp, int_pts_temp[pts_len-1])):\n",
    "            true_mid = int_pts_temp[0]\n",
    "        else:\n",
    "            true_mid = int_pts_temp[pts_len-1]\n",
    "    else:\n",
    "        true_mid = mid_temp\n",
    "        \n",
    "    midpointline = [true_mid, maxP]\n",
    "    \n",
    "    startPt = maxP\n",
    "    endPt = minP\n",
    "    if(use_bottom_midpoint):\n",
    "        endPt = true_mid\n",
    "    \n",
    "    #Get vector from start point to end point\n",
    "    v1 = (endPt[0] - startPt[0], endPt[1] - startPt[1])\n",
    "    vd = math.sqrt(v1[0]*v1[0]+v1[1]*v1[1])\n",
    "    v1norm = (v1[0]/vd, v1[1]/vd)    \n",
    "    \n",
    "    #Get step size/distance    \n",
    "    distance = get_dist(startPt, endPt) \n",
    "    h = distance/K    \n",
    "#     d_test = int(h*float(K))    \n",
    "#     true_k = K\n",
    "#     if(d_test>distance):\n",
    "#         true_k = true_k-1    \n",
    "    true_k = K\n",
    "\n",
    "    #Variables for the loop initialisation\n",
    "    start = (startPt[0], startPt[1])\n",
    "    start = get_p_at_d(start, v1norm, -h)\n",
    "    vol = 0\n",
    "    segments = []    \n",
    "    start = startPt\n",
    "    has_intersections = True\n",
    "    index = -1\n",
    "    blank_rgb = get_rgb_image(np.zeros((mask_rgb.shape[0],mask_rgb.shape[1])))\n",
    "    while(has_intersections):        \n",
    "        width = 0\n",
    "        index += 1\n",
    "        \n",
    "        #Get point along the line starting from startPt and taking a distance of h\n",
    "        #Get vect between the next point and the previous point        \n",
    "        end = get_p_at_d(start, (v1norm[0], v1norm[1]), h)        \n",
    "        vH = (end[0] - start[0], end[1] - start[1])\n",
    "        start = (end[0], end[1])\n",
    "        \n",
    "        #Safety to get out of the loop\n",
    "        if(get_dist(startPt, end) >= dr*1.1):\n",
    "            has_intersections = False\n",
    "            break\n",
    "        \n",
    "        #Rotate vect by 90 to get the horizontal cutting line\n",
    "        vPerp = (vH[1],vH[0]*-1.0)\n",
    "        vPerp_norm = get_norm(vPerp)\n",
    "\n",
    "        #Extend length of horizontal line to make sure it cuts\n",
    "        phoriz1 = get_p_at_d(end, vPerp_norm, -dr)\n",
    "        phoriz2 = get_p_at_d(end, vPerp_norm, dr)        \n",
    "        \n",
    "        p1 = phoriz1\n",
    "        p2 = phoriz2    \n",
    "        int_pts = get_intersection(blank_rgb, poly_points, p1, p2)        \n",
    "        \n",
    "        if(len(int_pts) == 2):\n",
    "            int1 = int_pts[0]\n",
    "            int2 = int_pts[1]\n",
    "            int_pt1 = (float(int1[0]),float(int1[1]))\n",
    "            int_pt2 = (float(int2[0]),float(int2[1]))\n",
    "            width = get_dist(int_pt1, int_pt2)            \n",
    "            segments.append((int_pt1,int_pt2)) \n",
    "            \n",
    "        elif (len(int_pts) > 2):\n",
    "            #just append the first and last for now\n",
    "            p1 = int_pts[0]\n",
    "            p2 = int_pts[len(int_pts)-1]\n",
    "            int_pt1 = (float(p1[0]),float(p1[1]))\n",
    "            int_pt2 = (float(p2[0]),float(p2[1]))\n",
    "            width += get_dist(int_pt1, int_pt2)            \n",
    "            segments.append((int_pt1,int_pt2)) \n",
    "        else:\n",
    "            #len(int_pts) is zero or one here            \n",
    "            has_intersections = False\n",
    "            break        \n",
    "        \n",
    "        rad = width/2.0\n",
    "        vol += math.pi*rad*rad*h   \n",
    "        \n",
    "    return vol, poly_points, minmaxline, midpointline, segments\n",
    "\n",
    "def get_mask_volume_quick_pixelspace(mask, pixelspace, K=20, is_binary_image = True):\n",
    "    '''\n",
    "    Computes the volume of the mask with the assumption that the \n",
    "    the the width of the segments are used as the radius of a cylinder.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mask : numpy array of 2 or 3 dimensions\n",
    "           This is a binary mask which means the values contained within\n",
    "           the array are 1 and 0 only.\n",
    "    K : int, optional\n",
    "        The number of segments(or cylinders) to divide the mask into. \n",
    "        The default is 20. \n",
    "        The greater the number the better the volume approximation, however,\n",
    "        the more computationally expensive it becomes.\n",
    "    is_binary_image : bool, optional\n",
    "        if true, then the input mask is expected to be a binary image.\n",
    "        Otherwise, it is a normal rgb image.\n",
    "        Example, if you're passing in an np.array from \n",
    "        tensorflow.model.predict' for a segmentation binary classification \n",
    "        problem, then this would be a binary image or binary mask.\n",
    "    use_bottom_midpoint : bool, optional\n",
    "        if this is true, the segments are based on the centerline from the \n",
    "        maximum point(top of LV) to the midpoint at the bottom of the LV. \n",
    "        If False, then the centerline runs from the max point to the min point.\n",
    "        The default is True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    use_bottom_midpoint = True\n",
    "\n",
    "    poly_points = None\n",
    "    midpointline = None\n",
    "    minmaxline = None\n",
    "    segments = None\n",
    "    \n",
    "    adj_mask = mask.copy()\n",
    "    \n",
    "    if is_binary_image:\n",
    "        if(len(mask.shape) == 3):\n",
    "            adj_mask = mask[:, :, 0]\n",
    "    \n",
    "    mask_rgb = adj_mask\n",
    "    \n",
    "    if is_binary_image:\n",
    "        mask_rgb = get_rgb_image(adj_mask)\n",
    "\n",
    "    #Get polyline of the mask    \n",
    "    image_test1_gray = cv2.cvtColor(mask_rgb, cv2.COLOR_BGR2GRAY)\n",
    "    contours, hierarchy = cv2.findContours(image_test1_gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    largest_index_area = 0\n",
    "    largest_area = -1\n",
    "    for i in range(0, len(contours)):\n",
    "        area = cv2.contourArea(contours[i])\n",
    "        if (area > largest_area):\n",
    "            largest_area = area\n",
    "            largest_index_area = i\n",
    "    \n",
    "    if(largest_area <= 0):\n",
    "        return 0, None, None, None, None\n",
    "\n",
    "    #Get the shape/polyline of the largest area    \n",
    "    poly_points = contours[largest_index_area]    \n",
    "    \n",
    "    #get the bounds\n",
    "    box = cv2.boundingRect(poly_points);\n",
    "    length_vert = (box[1]+box[3]) - box[1]\n",
    "    length_hori = (box[0]+box[2]) - box[0]\n",
    "    min_row = box[1] - length_vert\n",
    "    max_row = box[1] + box[3] + length_vert\n",
    "    min_col = box[0] - length_hori\n",
    "    max_col = box[0] + box[2] + length_hori\n",
    "\n",
    "    #Find the two points furthest apart\n",
    "    #While looping through all points, Also find the bottom-left most point and the bottom-right most point\n",
    "    index1 = -1\n",
    "    index2 = -1\n",
    "    dr = -999999999999.00\n",
    "    d_left = 999999999999.00\n",
    "    d_right = 999999999999.00\n",
    "    left_index = -1\n",
    "    right_index = -1\n",
    "    for i in range(len(poly_points)):\n",
    "        coord1 = poly_points[i][0]\n",
    "        x1 = coord1[0]\n",
    "        y1 = coord1[1]\n",
    "        for j in range(len(poly_points)):\n",
    "            if(i==j):\n",
    "                continue\n",
    "            coord2 = poly_points[j][0]\n",
    "            x2 = coord2[0]\n",
    "            y2 = coord2[1]        \n",
    "\n",
    "            d = math.sqrt(pow(x2-x1,2) + pow(y2-y1,2))\n",
    "            if(d>dr):\n",
    "                dr = d\n",
    "                index1 = i\n",
    "                index2 = j\n",
    "        \n",
    "        d1 = get_dist(coord1, (min_col, max_row))\n",
    "        d2 = get_dist(coord1,(max_col, max_row))\n",
    "        if(d1 < d_left):\n",
    "            d_left = d1\n",
    "            left_index = i\n",
    "        if(d2 < d_right):\n",
    "            d_right = d2\n",
    "            right_index = i        \n",
    "\n",
    "    coord1 = poly_points[index1][0]\n",
    "    coord2 = poly_points[index2][0]\n",
    "    \n",
    "    #Find min and max and get vect between them\n",
    "    minP = None\n",
    "    maxP = None\n",
    "\n",
    "    if(coord1[1] > coord2[1]):\n",
    "        minP = coord1\n",
    "        maxP = coord2\n",
    "    else:\n",
    "        minP = coord2\n",
    "        maxP = coord1\n",
    "        \n",
    "    minmaxline = [minP, maxP]\n",
    "        \n",
    "    #Get the midpoint\n",
    "    leftMost = poly_points[left_index][0]\n",
    "    rightMost = poly_points[right_index][0]\n",
    "    mid_temp = get_mid(leftMost, rightMost)    \n",
    "    \n",
    "    #create sympy polygon object\n",
    "    pts_temp = []\n",
    "    for i in range(len(poly_points)):\n",
    "        coord = poly_points[i][0]\n",
    "        x1 = coord[0]\n",
    "        y1 = coord[1]\n",
    "        pt = Point(x1,y1)\n",
    "        pts_temp.append(pt)    \n",
    "    \n",
    "    #Get vector from max point to mid point\n",
    "    v1 = (maxP[0] - mid_temp[0], maxP[1] - mid_temp[1])\n",
    "    vd = math.sqrt(v1[0]*v1[0]+v1[1]*v1[1])\n",
    "    v1norm = (v1[0]/vd, v1[1]/vd)    \n",
    "    \n",
    "    #Find the true midpoint     \n",
    "    p1_temp = get_p_at_d(maxP, v1norm, dr)\n",
    "    p2_temp = get_p_at_d(maxP, v1norm, -dr*1.10)    \n",
    "    \n",
    "    int_pts_temp = get_intersection(mask_rgb, poly_points, p1_temp, p2_temp)   \n",
    "    pts_len = len(int_pts_temp)\n",
    "    true_mid = None\n",
    "    #There should only be 2 points of intersection\n",
    "    if(len(int_pts_temp) >= 2):\n",
    "        if(get_dist(mid_temp, int_pts_temp[0]) < get_dist(mid_temp, int_pts_temp[pts_len-1])):\n",
    "            true_mid = int_pts_temp[0]\n",
    "        else:\n",
    "            true_mid = int_pts_temp[pts_len-1]\n",
    "    else:\n",
    "        true_mid = mid_temp\n",
    "        \n",
    "    midpointline = [true_mid, maxP]\n",
    "    \n",
    "    startPt = maxP\n",
    "    endPt = minP\n",
    "    if(use_bottom_midpoint):\n",
    "        endPt = true_mid\n",
    "    \n",
    "    #Get vector from start point to end point\n",
    "    v1 = (endPt[0] - startPt[0], endPt[1] - startPt[1])\n",
    "    vd = math.sqrt(v1[0]*v1[0]+v1[1]*v1[1])\n",
    "    v1norm = (v1[0]/vd, v1[1]/vd)    \n",
    "    \n",
    "    #Get step size/distance    \n",
    "    distance = get_dist(startPt, endPt) \n",
    "    h = distance/K    \n",
    "    \n",
    "    distance_conv = get_dist((startPt[0] * pixelspace[0], startPt[1] * pixelspace[1]) , (endPt[0] * pixelspace[0], endPt[1] * pixelspace[1]))\n",
    "    h_conv = distance/K    \n",
    "    \n",
    "#     d_test = int(h*float(K))    \n",
    "#     true_k = K\n",
    "#     if(d_test>distance):\n",
    "#         true_k = true_k-1    \n",
    "    true_k = K\n",
    "\n",
    "    #Variables for the loop initialisation\n",
    "    start = (startPt[0], startPt[1])\n",
    "    start = get_p_at_d(start, v1norm, -h)\n",
    "    vol = 0\n",
    "    segments = []    \n",
    "    start = startPt\n",
    "    has_intersections = True\n",
    "    index = -1\n",
    "    blank_rgb = get_rgb_image(np.zeros((mask_rgb.shape[0],mask_rgb.shape[1])))\n",
    "    while(has_intersections):        \n",
    "        width = 0\n",
    "        index += 1\n",
    "        \n",
    "        #Get point along the line starting from startPt and taking a distance of h\n",
    "        #Get vect between the next point and the previous point        \n",
    "        end = get_p_at_d(start, (v1norm[0], v1norm[1]), h)        \n",
    "        vH = (end[0] - start[0], end[1] - start[1])\n",
    "        start = (end[0], end[1])\n",
    "        \n",
    "        #Safety to get out of the loop\n",
    "        if(get_dist(startPt, end) >= dr*1.1):\n",
    "            has_intersections = False\n",
    "            break\n",
    "        \n",
    "        #Rotate vect by 90 to get the horizontal cutting line\n",
    "        vPerp = (vH[1],vH[0]*-1.0)\n",
    "        vPerp_norm = get_norm(vPerp)\n",
    "\n",
    "        #Extend length of horizontal line to make sure it cuts\n",
    "        phoriz1 = get_p_at_d(end, vPerp_norm, -dr)\n",
    "        phoriz2 = get_p_at_d(end, vPerp_norm, dr)        \n",
    "        \n",
    "        p1 = phoriz1\n",
    "        p2 = phoriz2    \n",
    "        int_pts = get_intersection(blank_rgb, poly_points, p1, p2)        \n",
    "        \n",
    "        if(len(int_pts) == 2):\n",
    "            int1 = int_pts[0] \n",
    "            int2 = int_pts[1]\n",
    "            int_pt1 = (float(int1[0]) * pixelspace[0] , float(int1[1]) * pixelspace[1])\n",
    "            int_pt2 = (float(int2[0]) * pixelspace[0] , float(int2[1]) * pixelspace[1])\n",
    "            width = get_dist(int_pt1, int_pt2)   \n",
    "            \n",
    "            int_pt1 = (float(int1[0]), float(int1[1]))\n",
    "            int_pt2 = (float(int2[0]), float(int2[1]))\n",
    "            segments.append((int_pt1,int_pt2)) \n",
    "            \n",
    "        elif (len(int_pts) > 2):\n",
    "            #just append the first and last for now\n",
    "            p1 = int_pts[0]\n",
    "            p2 = int_pts[len(int_pts)-1]\n",
    "            int_pt1 = (float(p1[0]) * pixelspace[0] , float(p1[1]) * pixelspace[1])\n",
    "            int_pt2 = (float(p2[0]) * pixelspace[0] , float(p2[1]) * pixelspace[1])\n",
    "            width += get_dist(int_pt1, int_pt2)\n",
    "            \n",
    "            int_pt1 = (float(p1[0]), float(p1[1]))\n",
    "            int_pt2 = (float(p2[0]), float(p2[1]))\n",
    "            segments.append((int_pt1,int_pt2)) \n",
    "        else:\n",
    "            #len(int_pts) is zero or one here            \n",
    "            has_intersections = False\n",
    "            break        \n",
    "        \n",
    "        rad = width/2.0\n",
    "        vol += math.pi*rad*rad* h_conv   \n",
    "        \n",
    "    return vol, poly_points, minmaxline, midpointline, segments\n",
    "\n",
    "def annotate_image(mask, polypoints, minmaxline, midpointline, segments, is_binary_image = True):\n",
    "    \n",
    "    adj_mask = mask.copy()\n",
    "    \n",
    "    if is_binary_image:\n",
    "        if(len(mask.shape) == 3):\n",
    "            adj_mask = mask[:, :, 0]\n",
    "        \n",
    "    mask_rgb = adj_mask\n",
    "    \n",
    "    if is_binary_image:\n",
    "        mask_rgb = get_rgb_image(adj_mask)\n",
    "    \n",
    "    #Draw the shape/polyline of the largest area onto the mask\n",
    "    if not polypoints is None:        \n",
    "        mask_rgb = draw_poly_on_image(mask_rgb, polypoints, (255,255,0), False)\n",
    "    \n",
    "    #Draw the line between the two farthest points of the polyline.\n",
    "    if not minmaxline is None:\n",
    "        minP = minmaxline[0]\n",
    "        maxP = minmaxline[1]\n",
    "        mask_rgb = draw_line_on_image(mask_rgb, minP[0], minP[1], maxP[0], maxP[1], (0,255,0), False)\n",
    "    \n",
    "    #Draw the line between the highest point and the bottom mid-point.\n",
    "    if not midpointline is None:\n",
    "        midP = midpointline[0]\n",
    "        maxP = midpointline[1]\n",
    "        mask_rgb = draw_line_on_image(mask_rgb, midP[0], midP[1], maxP[0], maxP[1], (255,0,255), False)\n",
    "    \n",
    "    #Draw the lines of the segments that run accross the mask\n",
    "    if not segments is None:\n",
    "        for segment in segments:\n",
    "            int_pt1 = segment[0]\n",
    "            int_pt2 = segment[1]\n",
    "            mask_rgb = draw_line_on_image(mask_rgb, int_pt1[0], int_pt1[1], int_pt2[0], int_pt2[1], (255,0,0), use_weight = False)\n",
    "            mask_rgb = draw_circle_on_image(mask_rgb, int_pt1[0], int_pt1[1], 2, (0,0,255), False)\n",
    "            mask_rgb = draw_circle_on_image(mask_rgb, int_pt2[0], int_pt2[1], 2, (0,0,255), False)\n",
    "            \n",
    "    return mask_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb93508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_np_from_file(filename, index):\n",
    "    \n",
    "    new_file_name = f'{filename}.pkl'\n",
    "    if not(index is None):\n",
    "        new_file_name = f'{filename}_{index}.pkl'    \n",
    "    \n",
    "    with open(new_file_name, 'rb') as filehandle:\n",
    "        return pickle.load(filehandle)\n",
    "    \n",
    "    \n",
    "def save_np_to_file(filename, index, data):\n",
    "    \n",
    "    new_file_name = f'{filename}.pkl'\n",
    "    if not(index is None):\n",
    "        new_file_name = f'{filename}_{index}.pkl'        \n",
    "    \n",
    "    with open(new_file_name, 'wb') as filehandle:\n",
    "        pickle.dump(data, filehandle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb935a7",
   "metadata": {},
   "source": [
    "# MAKE PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b64639",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(LOCAL_DATA_PATH, 'images/training')\n",
    "test_dir = os.path.join(LOCAL_DATA_PATH, 'images/testing')\n",
    "val_dir = os.path.join(LOCAL_DATA_PATH, 'images/validation')\n",
    "annot_dir = os.path.join(LOCAL_DATA_PATH, 'annotations_binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786a6107",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dir)\n",
    "print(val_dir)\n",
    "print(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c185f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_files = os.listdir(train_dir)\n",
    "test_files = os.listdir(test_dir)\n",
    "#val_files = os.listdir(val_dir)\n",
    "\n",
    "#for i in range(0, len(train_files)):\n",
    "#    filename = train_files[i]\n",
    "#    train_files[i] = os.path.join(train_dir, filename)\n",
    "    \n",
    "for i in range(0, len(test_files)):\n",
    "    filename = test_files[i]\n",
    "    test_files[i] = os.path.join(test_dir, filename)\n",
    "    \n",
    "#for i in range(0, len(val_files)):\n",
    "#    filename = val_files[i]\n",
    "#    val_files[i] = os.path.join(val_dir, filename)\n",
    "\n",
    "#random.shuffle(train_files)\n",
    "#random.shuffle(test_files)\n",
    "#random.shuffle(val_files)\n",
    "\n",
    "#print(f'Training File Count: {len(train_files)}')\n",
    "#print(f'Validation File Count: {len(val_files)}')\n",
    "print(f'Test File Size: {len(test_files)}') \n",
    "\n",
    "test_files.sort()\n",
    "\n",
    "for i in range(10):\n",
    "    print(test_files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54e249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_volume_of_masks(masks):\n",
    "    \n",
    "    num_examples = len(masks)\n",
    "    all_vol = {}\n",
    "    all_imgs = {}\n",
    "    sum_vol = 0\n",
    "    \n",
    "    for i in range(num_examples):\n",
    "        mask = masks[i]        \n",
    "        vol, poly_points, minmaxline, midpointline, segments = get_mask_volume_quick(mask, K=50)\n",
    "        img = annotate_image(mask, poly_points, None, midpointline, segments)\n",
    "        sum_vol+= vol\n",
    "        all_vol[i] = vol\n",
    "        all_imgs[i] = img\n",
    "        \n",
    "    avg_vol = (sum_vol)/num_examples\n",
    "    \n",
    "    return avg_vol, all_vol, all_imgs\n",
    "\n",
    "def get_avg_volume_of_masks_pixelspace(masks, pixelspaces):\n",
    "    \n",
    "    num_examples = len(masks)\n",
    "    all_vol = {}\n",
    "    all_imgs = {}\n",
    "    sum_vol = 0\n",
    "    \n",
    "    for i in range(num_examples):\n",
    "        mask = masks[i]      \n",
    "        pixelspace1 = pixelspaces[i]\n",
    "        vol, poly_points, minmaxline, midpointline, segments = get_mask_volume_quick_pixelspace(mask, pixelspace1, K=100)\n",
    "        img = annotate_image(mask, poly_points, None, midpointline, segments)\n",
    "        sum_vol+= vol\n",
    "        all_vol[i] = vol\n",
    "        all_imgs[i] = img\n",
    "        \n",
    "    avg_vol = (sum_vol)/num_examples\n",
    "    \n",
    "    return avg_vol, all_vol, all_imgs\n",
    "\n",
    "def split_into_parts(volumes):\n",
    "    ED_vols = {}\n",
    "    ES_vols = {}\n",
    "    \n",
    "    c=0\n",
    "    for i in range(0, len(volumes), 2):\n",
    "        edv = volumes[i]\n",
    "        esv = volumes[i+1]\n",
    "        ED_vols[c] = edv\n",
    "        ES_vols[c] = esv\n",
    "        c+=1\n",
    "        \n",
    "    return ED_vols, ES_vols\n",
    "\n",
    "def compute_ejection_fraction(ED_volumes, ES_volumes):\n",
    "    \n",
    "    num_examples = len(ED_volumes)\n",
    "    all_ef = {}\n",
    "    sum_ef = 0\n",
    "    \n",
    "    for i in range(num_examples):\n",
    "        EDV = ED_volumes[i]\n",
    "        ESV = ES_volumes[i]\n",
    "        \n",
    "        if(ESV>EDV):\n",
    "            temp = ESV\n",
    "            ESV = EDV\n",
    "            EDV = temp\n",
    "        \n",
    "        stroke_volume = EDV - ESV\n",
    "        ejection_fraction = 0\n",
    "        if (EDV > 0):\n",
    "            ejection_fraction = (stroke_volume / EDV) * 100.0\n",
    "        sum_ef += ejection_fraction\n",
    "        all_ef[i] = ejection_fraction\n",
    "        \n",
    "    avg_ef = (sum_ef)/num_examples\n",
    "    \n",
    "    return avg_ef, all_ef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac314929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overlay_image(echo_image, gt, pred):\n",
    "    img_gt = gt\n",
    "    img_pred= pred\n",
    "\n",
    "    #Get polyline of the mask    \n",
    "    image_test1_gray = cv2.cvtColor(img_gt, cv2.COLOR_BGR2GRAY)\n",
    "    contours, hierarchy = cv2.findContours(image_test1_gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    largest_index_area = 0\n",
    "    largest_area = -1\n",
    "    for i in range(0, len(contours)):\n",
    "        area = cv2.contourArea(contours[i])\n",
    "        if (area > largest_area):\n",
    "            largest_area = area\n",
    "            largest_index_area = i\n",
    "\n",
    "    #Get the shape/polyline of the largest area    \n",
    "    poly_points = contours[largest_index_area]\n",
    "\n",
    "    #Get polyline of the mask    \n",
    "    image_test1_gray = cv2.cvtColor(img_pred, cv2.COLOR_BGR2GRAY)\n",
    "    contours, hierarchy = cv2.findContours(image_test1_gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    largest_index_area = 0\n",
    "    largest_area = -1\n",
    "    for i in range(0, len(contours)):\n",
    "        area = cv2.contourArea(contours[i])\n",
    "        if (area > largest_area):\n",
    "            largest_area = area\n",
    "            largest_index_area = i\n",
    "\n",
    "    #Get the shape/polyline of the largest area    \n",
    "    poly_pointsp = contours[largest_index_area]   \n",
    "\n",
    "    img8 = draw_poly_on_image_weight(echo_image, poly_points, (255,0,0), 4)\n",
    "    img8p = draw_poly_on_image_weight(img8, poly_pointsp, (0,255,0), 4)\n",
    "\n",
    "    return img8p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad2e488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_points(mask, is_binary_image = True):\n",
    "    '''\n",
    "    Gets the points of the predicted mask outline, as well as \n",
    "    the bottom left-most and right-most points.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mask : numpy array of 2 or 3 dimensions\n",
    "           This is a binary mask which means the values contained within\n",
    "           the array are 1 and 0 only.    \n",
    "    is_binary_image : bool, optional\n",
    "        if true, then the input mask is expected to be a binary image.\n",
    "        Otherwise, it is a normal rgb image.\n",
    "        Example, if you're passing in an np.array from \n",
    "        tensorflow.model.predict' for a segmentation binary classification \n",
    "        problem, then this would be a binary image or binary mask.\n",
    "    use_bottom_midpoint : bool, optional\n",
    "        if this is true, the segments are based on the centerline from the \n",
    "        maximum point(top of LV) to the midpoint at the bottom of the LV. \n",
    "        If False, then the centerline runs from the max point to the min point.\n",
    "        The default is True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    use_bottom_midpoint = True\n",
    "\n",
    "    poly_points = None\n",
    "    midpointline = None\n",
    "    minmaxline = None\n",
    "    segments = None\n",
    "    \n",
    "    adj_mask = mask.copy()\n",
    "    \n",
    "    if is_binary_image:\n",
    "        if(len(mask.shape) == 3):\n",
    "            adj_mask = mask[:, :, 0]\n",
    "    \n",
    "    mask_rgb = adj_mask\n",
    "    \n",
    "    if is_binary_image:\n",
    "        mask_rgb = get_rgb_image(adj_mask)\n",
    "\n",
    "    #Get polyline of the mask    \n",
    "    image_test1_gray = cv2.cvtColor(mask_rgb, cv2.COLOR_BGR2GRAY)\n",
    "    contours, hierarchy = cv2.findContours(image_test1_gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    largest_index_area = 0\n",
    "    largest_area = -1\n",
    "    for i in range(0, len(contours)):\n",
    "        area = cv2.contourArea(contours[i])\n",
    "        if (area > largest_area):\n",
    "            largest_area = area\n",
    "            largest_index_area = i\n",
    "    \n",
    "    if(largest_area <= 0):\n",
    "        return 0, None, None, None, None\n",
    "\n",
    "    #Get the shape/polyline of the largest area    \n",
    "    poly_points = contours[largest_index_area]    \n",
    "    \n",
    "    #get the bounds\n",
    "    box = cv2.boundingRect(poly_points);\n",
    "    length_vert = (box[1]+box[3]) - box[1]\n",
    "    length_hori = (box[0]+box[2]) - box[0]\n",
    "    min_row = box[1] - length_vert\n",
    "    max_row = box[1] + box[3] + length_vert\n",
    "    min_col = box[0] - length_hori\n",
    "    max_col = box[0] + box[2] + length_hori\n",
    "\n",
    "    #Find the two points furthest apart\n",
    "    #While looping through all points, Also find the bottom-left most point and the bottom-right most point\n",
    "    index1 = -1\n",
    "    index2 = -1\n",
    "    dr = -999999999999.00\n",
    "    d_left = 999999999999.00\n",
    "    d_right = 999999999999.00\n",
    "    left_index = -1\n",
    "    right_index = -1\n",
    "    for i in range(len(poly_points)):\n",
    "        coord1 = poly_points[i][0]\n",
    "        x1 = coord1[0]\n",
    "        y1 = coord1[1]\n",
    "        for j in range(len(poly_points)):\n",
    "            if(i==j):\n",
    "                continue\n",
    "            coord2 = poly_points[j][0]\n",
    "            x2 = coord2[0]\n",
    "            y2 = coord2[1]        \n",
    "\n",
    "            d = math.sqrt(pow(x2-x1,2) + pow(y2-y1,2))\n",
    "            if(d>dr):\n",
    "                dr = d\n",
    "                index1 = i\n",
    "                index2 = j\n",
    "        \n",
    "        d1 = get_dist(coord1, (min_col, max_row))\n",
    "        d2 = get_dist(coord1,(max_col, max_row))\n",
    "        if(d1 < d_left):\n",
    "            d_left = d1\n",
    "            left_index = i\n",
    "        if(d2 < d_right):\n",
    "            d_right = d2\n",
    "            right_index = i        \n",
    "\n",
    "    coord1 = poly_points[index1][0]\n",
    "    coord2 = poly_points[index2][0]\n",
    "    \n",
    "    #Find min and max and get vect between them\n",
    "    minP = None\n",
    "    maxP = None\n",
    "\n",
    "    if(coord1[1] > coord2[1]):\n",
    "        minP = coord1\n",
    "        maxP = coord2\n",
    "    else:\n",
    "        minP = coord2\n",
    "        maxP = coord1\n",
    "        \n",
    "    minmaxline = [minP, maxP]\n",
    "        \n",
    "    #Get the midpoint\n",
    "    leftMost = poly_points[left_index][0]\n",
    "    rightMost = poly_points[right_index][0]\n",
    "    mid_temp = get_mid(leftMost, rightMost)\n",
    "    \n",
    "    return poly_points, leftMost, rightMost\n",
    "\n",
    "def get_bin_mask(trim_mask):\n",
    "    bin_mask = np.zeros(trim_mask.shape)\n",
    "\n",
    "    for i in range(trim_mask.shape[0]):\n",
    "        for j in range(trim_mask.shape[1]): \n",
    "            if(trim_mask[i,j] == 255):\n",
    "                bin_mask[i,j] = 1\n",
    "                \n",
    "    return bin_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccece65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from loss_functions import *\n",
    "loss_funcs = Semantic_loss_functions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa453a31",
   "metadata": {},
   "source": [
    "# Variables to store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac8781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_names = []\n",
    "loss_names = ['BinaryCrossEntropy loss', 'Dice loss', 'BCE & Dice loss', 'Tversky loss', 'Focal Tversky loss' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6667afe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_exp_volume_errors = [0,0,0,0,0]\n",
    "avg_exp_volumes = [0,0,0,0,0]\n",
    "avg_exp_volumes_predicted = [0,0,0,0,0]\n",
    "avg_exp_dice = [0,0,0,0,0]\n",
    "avg_exp_dh = [0,0,0,0,0]\n",
    "avg_exp_EF = [0,0,0,0,0]\n",
    "avg_exp_EFp = [0,0,0,0,0]\n",
    "avg_exp_EF_Err = [0,0,0,0,0]\n",
    "\n",
    "all_vols_ED = []\n",
    "all_vols_ES = []\n",
    "all_vols_pred_ED = []\n",
    "all_vols_pred_ES = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141fa768",
   "metadata": {},
   "source": [
    "## INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a7efb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'Echonet Tversky Loss Model tested on Echo Test Dataset'\n",
    "model_path = MODEL_PATH\n",
    "test_files = test_files\n",
    "loss_function = loss_funcs.tversky_loss\n",
    "\n",
    "model = keras.models.load_model(model_path, compile = False)\n",
    "model.compile(optimizer=Adam(lr=LEARNING_RATE),\n",
    "                  loss=loss_function,\n",
    "                  metrics=['accuracy'], run_eagerly=True\n",
    "                 )\n",
    "\n",
    "all_predicted_masks, all_ground_truth_masks, all_probabilities = make_predictions(model, test_files)\n",
    "avg_dH, all_dHs = get_Hausdorff_distance(all_predicted_masks, all_ground_truth_masks)\n",
    "avg_dice, all_dice = get_Dice_Coefficient(all_predicted_masks, all_ground_truth_masks)    \n",
    "     \n",
    "print(f'Number of predicted Masks : {len(all_predicted_masks)}')\n",
    "print('Completed All Predictions')\n",
    "\n",
    "avg_vol, all_vol, all_imgs = get_avg_volume_of_masks(all_ground_truth_masks)\n",
    "avg_volp, all_volp, all_imgsp = get_avg_volume_of_masks(all_predicted_masks)\n",
    "print('Completed All Volume Computations')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c16c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ED_vols, ES_vols = split_into_parts(all_vol)\n",
    "avg_ef, all_ef = compute_ejection_fraction(ED_vols, ES_vols)\n",
    "\n",
    "ED_volsp, ES_volsp = split_into_parts(all_volp)\n",
    "avg_efp, all_efp = compute_ejection_fraction(ED_volsp, ES_volsp)\n",
    "\n",
    "all_vols_ED.append(list(ED_vols.values()))\n",
    "all_vols_ES.append(list(ES_vols.values()))\n",
    "all_vols_pred_ED.append(list(ED_volsp.values()))\n",
    "all_vols_pred_ES.append(list(ES_volsp.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc064265",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(experiment_name)\n",
    "print()\n",
    "#print(f'CAMMUS Training File Count: {len(train_files)}')\n",
    "#print(f'CAMMUS Validation File Count: {len(val_files)}')\n",
    "print(f'Echonet Test File Size: {len(test_files)}') \n",
    "print()\n",
    "print(f'Average HD: {avg_dH}')\n",
    "print(f'Average DICE: {avg_dice}')\n",
    "print(f'Average Ground Truth Volume: {avg_vol}') \n",
    "print(f'Average Predicted Mask Volume: {avg_volp}')\n",
    "print(f'Average Volume Error: {abs(avg_vol-avg_volp)}')\n",
    "print(f'Average Ground Truth Ejection Fraction: {avg_ef}') \n",
    "print(f'Average Predicted Ejection Fraction: {avg_efp}')\n",
    "print(f'Average Ejection Fraction Error: {abs(avg_ef-avg_efp)}')\n",
    "\n",
    "avg_exp_volume_errors[3] = abs(avg_vol-avg_volp)\n",
    "avg_exp_volumes[3] = avg_vol\n",
    "avg_exp_volumes_predicted[3] = avg_volp\n",
    "avg_exp_dice[3] = avg_dice\n",
    "avg_exp_dh[3] = avg_dH\n",
    "avg_exp_EF[3] = avg_ef\n",
    "avg_exp_EFp[3] = avg_efp\n",
    "avg_exp_EF_Err[3] = abs(avg_ef-avg_efp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43429346",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_path = 'Predictions_binaries'\n",
    "predictions_gray_scale_path = 'Predictions_grayscale'\n",
    "gt_gray_scale_path = 'ground_truths_grayscale'\n",
    "overlay_path = 'Overlays'\n",
    "if not os.path.exists(predictions_path):\n",
    "    os.makedirs(predictions_path)\n",
    "if not os.path.exists(predictions_gray_scale_path):\n",
    "    os.makedirs(predictions_gray_scale_path)\n",
    "if not os.path.exists(gt_gray_scale_path):\n",
    "    os.makedirs(gt_gray_scale_path)\n",
    "if not os.path.exists(overlay_path):\n",
    "    os.makedirs(overlay_path)\n",
    "\n",
    "x=-1\n",
    "for i in range(len(all_imgs)):\n",
    "    if(i%2==0):\n",
    "        x+=1\n",
    "    echo = cv2.imread(test_files[i])\n",
    "    echo = cv2.resize(echo, (512,512), fx=1, fy=1)\n",
    "    overlay = get_overlay_image(echo, all_imgs[i], all_imgsp[i])\n",
    "    print('----------------------------------------------------------')\n",
    "    print(f'Index {i}')\n",
    "    print(test_files[i])\n",
    "    print(f'gt mask VOL:{all_vol[i]}')\n",
    "    print(f'pred mask VOL:{all_volp[i]}')\n",
    "    print(f'vol ERR:{abs(all_vol[i] - all_volp[i])}')    \n",
    "    \n",
    "    print(f'gt mask EF:{all_ef[x]}')\n",
    "    print(f'pred mask EF:{all_efp[x]}')\n",
    "    print(f'EF ERR:{abs(all_ef[x] - all_efp[x])}')\n",
    "    print(f'dice:{all_dice[i]}')\n",
    "    print(f'hd:{all_dHs[i]}')\n",
    "    display_list = [echo, all_imgs[i], all_imgsp[i]]\n",
    "    display(display_list)\n",
    "    print('----------------------------------------------------------')\n",
    "    \n",
    "    filename = os.path.basename(test_files[i])\n",
    "    cv2.imwrite(os.path.join(predictions_path, filename), all_predicted_masks[i])\n",
    "    image_test1_gray = get_rgb_image(all_predicted_masks[i])\n",
    "    cv2.imwrite(os.path.join(predictions_gray_scale_path, filename), image_test1_gray)\n",
    "    cv2.imwrite(os.path.join(gt_gray_scale_path, filename), get_rgb_image(all_ground_truth_masks[i]))\n",
    "    cv2.imwrite(os.path.join(overlay_path, filename), overlay)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7b8f71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3e53d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_vol))\n",
    "print(len(all_ef))\n",
    "\n",
    "output_csv_name = 'output_measurements.csv'\n",
    "\n",
    "with open(output_csv_name, 'w', newline='') as f:\n",
    "    \n",
    "    # create the csv writer\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['FILENAME', 'VOL GT MASK (pix)', 'EF GT MASK', 'VOL PRED MASK (pix)', 'EF PRED MASK', 'DICE', 'HD'])\n",
    "\n",
    "    x=-1\n",
    "    for i in range(len(all_imgs)):\n",
    "        \n",
    "        if(i%2==0):\n",
    "            x+=1\n",
    "        \n",
    "        filename = os.path.basename(test_files[i])        \n",
    "        # write a row to the csv file\n",
    "        writer.writerow([filename, all_vol[i], all_ef[x], all_volp[i], all_efp[x], all_dice[i], all_dHs[i]])\n",
    "\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90225662",
   "metadata": {},
   "source": [
    "## Display All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add2bddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "print('Cammus dataset (450 images split into train(350), val(50), test(50))')\n",
    "print('Model trained with Cammus dataset (train and val split)')\n",
    "print('Results for predictions and volume error on test set split is as follows:')\n",
    "\n",
    "info = {'Loss Function' : loss_names,\n",
    "        'Average EF Error' : avg_exp_EF_Err,\n",
    "        #'Average EF' : avg_exp_EF,\n",
    "        #'Average EF Pred' : avg_exp_EFp,\n",
    "        #'Average vol' : avg_exp_volumes,\n",
    "        #'Average vol Pred' : avg_exp_volumes_predicted}#,\n",
    "        'Average Vol Error' : avg_exp_volume_errors,\n",
    "        'Avg Dice Coeff' : avg_exp_dice,\n",
    "        'Avg Hausdorff Dist' : avg_exp_dh}\n",
    "\n",
    "print(tabulate(info, headers='keys', tablefmt='fancy_grid', floatfmt=\".4f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d39c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {'Loss Function' : loss_names,\n",
    "        #'Average EF Error' : avg_exp_EF_Err,\n",
    "        'Average EF' : avg_exp_EF,\n",
    "        'Average EF Pred' : avg_exp_EFp,\n",
    "        'Average vol' : avg_exp_volumes,\n",
    "        'Average vol Pred' : avg_exp_volumes_predicted}#,\n",
    "        #'Average Vol Error' : avg_exp_volume_errors,\n",
    "        #'Avg Dice Coeff' : avg_exp_dice,\n",
    "        #'Avg Hausdorff Dist' : avg_exp_dh}\n",
    "\n",
    "print(tabulate(info, headers='keys', tablefmt='fancy_grid', floatfmt=\".4f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d6eb18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
